#!/bin/bash

# åœ¨çº¿è€ƒè¯•ç³»ç»Ÿæ•°æ®å¤‡ä»½è„šæœ¬
# æä¾›å…¨é‡å¤‡ä»½ã€å¢é‡å¤‡ä»½å’Œè‡ªåŠ¨åŒ–å¤‡ä»½ç®¡ç†

set -e

# ====================
# å…¨å±€å˜é‡é…ç½®
# ====================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="${PROJECT_ROOT}/logs/backup-${TIMESTAMP}.log"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# å¤‡ä»½é…ç½®
COMPOSE_FILE="docker-compose.yml"
BACKUP_DIR="${PROJECT_ROOT}/backups"
RETENTION_DAYS=30
COMPRESS=true
ENCRYPT=false
ENCRYPTION_KEY=""

# æ•°æ®åº“é…ç½®
DB_HOST="localhost"
DB_PORT="3306"
DB_NAME="exam_system"
DB_USER="root"
DB_PASSWORD=""

# è¿œç¨‹å¤‡ä»½é…ç½®
REMOTE_BACKUP=false
REMOTE_HOST=""
REMOTE_USER=""
REMOTE_PATH=""
S3_BUCKET=""
S3_REGION=""

# ====================
# æ—¥å¿—å’Œè¾“å‡ºå‡½æ•°
# ====================

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] INFO:${NC} $1" | tee -a "$LOG_FILE"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARN:${NC} $1" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1" | tee -a "$LOG_FILE"
}

debug() {
    if [ "$VERBOSE" = true ]; then
        echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] DEBUG:${NC} $1" | tee -a "$LOG_FILE"
    fi
}

# ====================
# å¸®åŠ©ä¿¡æ¯
# ====================

show_help() {
    cat << EOF
åœ¨çº¿è€ƒè¯•ç³»ç»Ÿå¤‡ä»½å·¥å…·

ç”¨æ³•: $0 [é€‰é¡¹] <æ“ä½œ>

æ“ä½œ:
    full        å…¨é‡å¤‡ä»½
    incremental å¢é‡å¤‡ä»½
    restore     æ¢å¤å¤‡ä»½
    list        åˆ—å‡ºå¤‡ä»½æ–‡ä»¶
    cleanup     æ¸…ç†è¿‡æœŸå¤‡ä»½
    verify      éªŒè¯å¤‡ä»½å®Œæ•´æ€§
    schedule    è®¾ç½®è‡ªåŠ¨å¤‡ä»½

é€‰é¡¹:
    -h, --help              æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    -v, --verbose           è¯¦ç»†è¾“å‡ºæ¨¡å¼
    -d, --backup-dir <ç›®å½•>  å¤‡ä»½ç›®å½• (é»˜è®¤: ./backups)
    -r, --retention <å¤©æ•°>   ä¿ç•™å¤©æ•° (é»˜è®¤: 30)
    --no-compress           ä¸å‹ç¼©å¤‡ä»½æ–‡ä»¶
    --encrypt               åŠ å¯†å¤‡ä»½æ–‡ä»¶
    --encryption-key <å¯†é’¥>  åŠ å¯†å¯†é’¥
    --remote                å¯ç”¨è¿œç¨‹å¤‡ä»½
    --s3-bucket <bucket>    S3 å­˜å‚¨æ¡¶åç§°

ç¤ºä¾‹:
    $0 full                     # æ‰§è¡Œå…¨é‡å¤‡ä»½
    $0 incremental             # æ‰§è¡Œå¢é‡å¤‡ä»½
    $0 restore backup_20231201 # æ¢å¤æŒ‡å®šå¤‡ä»½
    $0 cleanup                 # æ¸…ç†è¿‡æœŸå¤‡ä»½
    $0 schedule --cron         # è®¾ç½®å®šæ—¶å¤‡ä»½

EOF
}

# ====================
# å‚æ•°è§£æ
# ====================

parse_arguments() {
    OPERATION=""
    VERBOSE=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -d|--backup-dir)
                BACKUP_DIR="$2"
                shift 2
                ;;
            -r|--retention)
                RETENTION_DAYS="$2"
                shift 2
                ;;
            --no-compress)
                COMPRESS=false
                shift
                ;;
            --encrypt)
                ENCRYPT=true
                shift
                ;;
            --encryption-key)
                ENCRYPTION_KEY="$2"
                shift 2
                ;;
            --remote)
                REMOTE_BACKUP=true
                shift
                ;;
            --s3-bucket)
                S3_BUCKET="$2"
                shift 2
                ;;
            full|incremental|restore|list|cleanup|verify|schedule)
                OPERATION="$1"
                if [ "$1" = "restore" ] && [ -n "$2" ] && [[ ! "$2" =~ ^- ]]; then
                    RESTORE_TARGET="$2"
                    shift
                fi
                shift
                ;;
            *)
                error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    if [ -z "$OPERATION" ]; then
        error "è¯·æŒ‡å®šæ“ä½œ"
        show_help
        exit 1
    fi
}

# ====================
# ç¯å¢ƒæ£€æŸ¥
# ====================

check_prerequisites() {
    log "æ£€æŸ¥å¤‡ä»½ç¯å¢ƒ..."
    
    # æ£€æŸ¥å¿…è¦å‘½ä»¤
    local required_commands=("docker" "docker-compose" "tar")
    
    if [ "$COMPRESS" = true ]; then
        required_commands+=("gzip")
    fi
    
    if [ "$ENCRYPT" = true ]; then
        required_commands+=("openssl")
    fi
    
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null; then
            error "ç¼ºå°‘å¿…è¦å‘½ä»¤: $cmd"
            exit 1
        fi
        debug "âœ“ $cmd å‘½ä»¤å¯ç”¨"
    done
    
    # æ£€æŸ¥ Docker æœåŠ¡
    if ! docker info &> /dev/null; then
        error "Docker æœåŠ¡æœªè¿è¡Œ"
        exit 1
    fi
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p "$BACKUP_DIR"
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    local available_space=$(df "$BACKUP_DIR" | awk 'NR==2 {print $4}')
    local required_space=10485760  # 10GB in KB
    
    if [ "$available_space" -lt "$required_space" ]; then
        warn "å¤‡ä»½ç›®å½•ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘ä¿ç•™ 10GB ç©ºé—´"
    fi
    
    log "ç¯å¢ƒæ£€æŸ¥å®Œæˆ"
}

# ====================
# MySQL æ•°æ®åº“å¤‡ä»½
# ====================

backup_mysql() {
    local backup_type="$1"
    local backup_file="$2"
    
    log "å¤‡ä»½ MySQL æ•°æ®åº“..."
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if ! docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T mysql-primary mysqladmin ping -h localhost &> /dev/null; then
        error "æ— æ³•è¿æ¥åˆ° MySQL æ•°æ®åº“"
        return 1
    fi
    
    local mysql_backup_file="${backup_file}/mysql_backup.sql"
    
    if [ "$backup_type" = "full" ]; then
        # å…¨é‡å¤‡ä»½
        debug "æ‰§è¡Œ MySQL å…¨é‡å¤‡ä»½"
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T mysql-primary \
            mysqldump -uroot -p"${MYSQL_ROOT_PASSWORD}" \
            --single-transaction \
            --routines \
            --triggers \
            --events \
            --all-databases \
            --master-data=2 \
            --flush-logs \
            > "$mysql_backup_file"
    else
        # å¢é‡å¤‡ä»½ (åŸºäºäºŒè¿›åˆ¶æ—¥å¿—)
        debug "æ‰§è¡Œ MySQL å¢é‡å¤‡ä»½"
        
        # è·å–æœ€åä¸€ä¸ªäºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶
        local last_binlog=$(docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T mysql-primary \
            mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW MASTER STATUS\G" | \
            grep File | awk '{print $2}')
        
        # å¤‡ä»½äºŒè¿›åˆ¶æ—¥å¿—
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T mysql-primary \
            mysqlbinlog --read-from-remote-server \
            --host=localhost \
            --user=root \
            --password="${MYSQL_ROOT_PASSWORD}" \
            "$last_binlog" > "${mysql_backup_file}.binlog"
    fi
    
    if [ $? -eq 0 ]; then
        log "âœ“ MySQL æ•°æ®åº“å¤‡ä»½å®Œæˆ"
        
        # è®°å½•å¤‡ä»½ä¿¡æ¯
        cat > "${backup_file}/mysql_info.json" << EOF
{
  "backup_type": "$backup_type",
  "database_name": "$DB_NAME",
  "backup_time": "$(date -Iseconds)",
  "file_size": $(stat -f%z "$mysql_backup_file" 2>/dev/null || stat -c%s "$mysql_backup_file" 2>/dev/null || echo 0),
  "checksum": "$(md5sum "$mysql_backup_file" | awk '{print $1}')"
}
EOF
        return 0
    else
        error "MySQL æ•°æ®åº“å¤‡ä»½å¤±è´¥"
        return 1
    fi
}

# ====================
# Redis æ•°æ®å¤‡ä»½
# ====================

backup_redis() {
    local backup_file="$1"
    
    log "å¤‡ä»½ Redis æ•°æ®..."
    
    # æ£€æŸ¥ Redis è¿æ¥
    if ! docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T redis-master redis-cli ping &> /dev/null; then
        error "æ— æ³•è¿æ¥åˆ° Redis"
        return 1
    fi
    
    # æ‰§è¡Œ BGSAVE
    docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T redis-master redis-cli BGSAVE
    
    # ç­‰å¾…å¤‡ä»½å®Œæˆ
    while true; do
        local save_in_progress=$(docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T redis-master \
            redis-cli LASTSAVE)
        
        sleep 2
        
        local current_save=$(docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T redis-master \
            redis-cli LASTSAVE)
        
        if [ "$save_in_progress" != "$current_save" ]; then
            break
        fi
    done
    
    # å¤åˆ¶ RDB æ–‡ä»¶
    local container_id=$(docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" ps -q redis-master)
    docker cp "$container_id:/data/dump.rdb" "${backup_file}/redis_dump.rdb"
    
    if [ $? -eq 0 ]; then
        log "âœ“ Redis æ•°æ®å¤‡ä»½å®Œæˆ"
        
        # è®°å½•å¤‡ä»½ä¿¡æ¯
        cat > "${backup_file}/redis_info.json" << EOF
{
  "backup_time": "$(date -Iseconds)",
  "file_size": $(stat -f%z "${backup_file}/redis_dump.rdb" 2>/dev/null || stat -c%s "${backup_file}/redis_dump.rdb" 2>/dev/null || echo 0),
  "checksum": "$(md5sum "${backup_file}/redis_dump.rdb" | awk '{print $1}')"
}
EOF
        return 0
    else
        error "Redis æ•°æ®å¤‡ä»½å¤±è´¥"
        return 1
    fi
}

# ====================
# æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½
# ====================

backup_filesystem() {
    local backup_file="$1"
    
    log "å¤‡ä»½æ–‡ä»¶ç³»ç»Ÿæ•°æ®..."
    
    # éœ€è¦å¤‡ä»½çš„ç›®å½•
    local backup_paths=(
        "${PROJECT_ROOT}/ssl"
        "${PROJECT_ROOT}/config"
        "${PROJECT_ROOT}/uploads"
        "${PROJECT_ROOT}/.env"
    )
    
    local filesystem_backup="${backup_file}/filesystem.tar"
    
    # åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿå¤‡ä»½
    tar -cf "$filesystem_backup" -C "$PROJECT_ROOT" \
        $(for path in "${backup_paths[@]}"; do
            if [ -e "$path" ]; then
                echo "$(basename "$path")"
            fi
        done) 2>/dev/null || true
    
    if [ -f "$filesystem_backup" ]; then
        log "âœ“ æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½å®Œæˆ"
        
        # è®°å½•å¤‡ä»½ä¿¡æ¯
        cat > "${backup_file}/filesystem_info.json" << EOF
{
  "backup_time": "$(date -Iseconds)",
  "file_size": $(stat -f%z "$filesystem_backup" 2>/dev/null || stat -c%s "$filesystem_backup" 2>/dev/null || echo 0),
  "checksum": "$(md5sum "$filesystem_backup" | awk '{print $1}')"
}
EOF
        return 0
    else
        warn "æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½ä¸ºç©ºæˆ–å¤±è´¥"
        return 1
    fi
}

# ====================
# å…¨é‡å¤‡ä»½
# ====================

full_backup() {
    log "å¼€å§‹æ‰§è¡Œå…¨é‡å¤‡ä»½..."
    
    local backup_name="full_backup_${TIMESTAMP}"
    local backup_path="${BACKUP_DIR}/${backup_name}"
    
    mkdir -p "$backup_path"
    
    # è®°å½•å¤‡ä»½å¼€å§‹ä¿¡æ¯
    cat > "${backup_path}/backup_info.json" << EOF
{
  "backup_id": "$backup_name",
  "backup_type": "full",
  "started_at": "$(date -Iseconds)",
  "hostname": "$(hostname)",
  "user": "${USER:-unknown}",
  "project_root": "$PROJECT_ROOT"
}
EOF
    
    local backup_success=true
    
    # å¤‡ä»½ MySQL
    if ! backup_mysql "full" "$backup_path"; then
        backup_success=false
    fi
    
    # å¤‡ä»½ Redis
    if ! backup_redis "$backup_path"; then
        backup_success=false
    fi
    
    # å¤‡ä»½æ–‡ä»¶ç³»ç»Ÿ
    if ! backup_filesystem "$backup_path"; then
        backup_success=false
    fi
    
    # æ›´æ–°å¤‡ä»½ä¿¡æ¯
    local end_time=$(date -Iseconds)
    local backup_size=$(du -sh "$backup_path" | awk '{print $1}')
    
    jq --arg end_time "$end_time" \
       --arg backup_size "$backup_size" \
       --argjson success "$backup_success" \
       '. + {completed_at: $end_time, backup_size: $backup_size, success: $success}' \
       "${backup_path}/backup_info.json" > "${backup_path}/backup_info.json.tmp" && \
       mv "${backup_path}/backup_info.json.tmp" "${backup_path}/backup_info.json"
    
    # å‹ç¼©å¤‡ä»½
    if [ "$COMPRESS" = true ]; then
        compress_backup "$backup_path"
    fi
    
    # åŠ å¯†å¤‡ä»½
    if [ "$ENCRYPT" = true ]; then
        encrypt_backup "$backup_path"
    fi
    
    # ä¸Šä¼ åˆ°è¿œç¨‹
    if [ "$REMOTE_BACKUP" = true ]; then
        upload_backup "$backup_path"
    fi
    
    if [ "$backup_success" = true ]; then
        log "ğŸ‰ å…¨é‡å¤‡ä»½å®Œæˆ: $backup_name"
        log "å¤‡ä»½å¤§å°: $backup_size"
        log "å¤‡ä»½è·¯å¾„: $backup_path"
    else
        error "å…¨é‡å¤‡ä»½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
        return 1
    fi
}

# ====================
# å¢é‡å¤‡ä»½
# ====================

incremental_backup() {
    log "å¼€å§‹æ‰§è¡Œå¢é‡å¤‡ä»½..."
    
    # æŸ¥æ‰¾æœ€è¿‘çš„å…¨é‡å¤‡ä»½
    local last_full_backup=$(find "$BACKUP_DIR" -name "full_backup_*" -type d | sort | tail -n 1)
    
    if [ -z "$last_full_backup" ]; then
        warn "æœªæ‰¾åˆ°å…¨é‡å¤‡ä»½ï¼Œæ‰§è¡Œå…¨é‡å¤‡ä»½"
        full_backup
        return
    fi
    
    local backup_name="incremental_backup_${TIMESTAMP}"
    local backup_path="${BACKUP_DIR}/${backup_name}"
    
    mkdir -p "$backup_path"
    
    # è®°å½•å¤‡ä»½ä¿¡æ¯
    cat > "${backup_path}/backup_info.json" << EOF
{
  "backup_id": "$backup_name",
  "backup_type": "incremental",
  "base_backup": "$(basename "$last_full_backup")",
  "started_at": "$(date -Iseconds)",
  "hostname": "$(hostname)",
  "user": "${USER:-unknown}"
}
EOF
    
    # æ‰§è¡Œå¢é‡å¤‡ä»½ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºå¤‡ä»½æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ï¼‰
    log "æ‰§è¡Œå¢é‡æ•°æ®å¤‡ä»½..."
    
    # MySQL å¢é‡å¤‡ä»½
    backup_mysql "incremental" "$backup_path"
    
    # æŸ¥æ‰¾è‡ªä¸Šæ¬¡å¤‡ä»½ä»¥æ¥ä¿®æ”¹çš„æ–‡ä»¶
    local last_backup_time=$(stat -f%m "$last_full_backup" 2>/dev/null || stat -c%Y "$last_full_backup" 2>/dev/null)
    find "$PROJECT_ROOT" -newer "$last_full_backup" -type f \
        -not -path "*/logs/*" \
        -not -path "*/backups/*" \
        -not -path "*/.git/*" \
        -exec cp --parents {} "$backup_path/" \; 2>/dev/null || true
    
    local end_time=$(date -Iseconds)
    local backup_size=$(du -sh "$backup_path" | awk '{print $1}')
    
    jq --arg end_time "$end_time" \
       --arg backup_size "$backup_size" \
       '. + {completed_at: $end_time, backup_size: $backup_size, success: true}' \
       "${backup_path}/backup_info.json" > "${backup_path}/backup_info.json.tmp" && \
       mv "${backup_path}/backup_info.json.tmp" "${backup_path}/backup_info.json"
    
    log "âœ“ å¢é‡å¤‡ä»½å®Œæˆ: $backup_name"
    log "å¤‡ä»½å¤§å°: $backup_size"
}

# ====================
# å‹ç¼©å¤‡ä»½
# ====================

compress_backup() {
    local backup_path="$1"
    local backup_name=$(basename "$backup_path")
    
    log "å‹ç¼©å¤‡ä»½æ–‡ä»¶..."
    
    cd "$BACKUP_DIR"
    tar -czf "${backup_name}.tar.gz" "$backup_name"
    
    if [ $? -eq 0 ]; then
        local original_size=$(du -sh "$backup_name" | awk '{print $1}')
        local compressed_size=$(du -sh "${backup_name}.tar.gz" | awk '{print $1}')
        
        log "âœ“ å¤‡ä»½å‹ç¼©å®Œæˆ"
        log "åŸå§‹å¤§å°: $original_size"
        log "å‹ç¼©åå¤§å°: $compressed_size"
        
        # åˆ é™¤åŸå§‹ç›®å½•
        rm -rf "$backup_name"
    else
        error "å¤‡ä»½å‹ç¼©å¤±è´¥"
        return 1
    fi
}

# ====================
# åŠ å¯†å¤‡ä»½
# ====================

encrypt_backup() {
    local backup_path="$1"
    local backup_file="${backup_path}.tar.gz"
    
    if [ -z "$ENCRYPTION_KEY" ]; then
        error "æœªæä¾›åŠ å¯†å¯†é’¥"
        return 1
    fi
    
    log "åŠ å¯†å¤‡ä»½æ–‡ä»¶..."
    
    openssl aes-256-cbc -salt -in "$backup_file" -out "${backup_file}.enc" -k "$ENCRYPTION_KEY"
    
    if [ $? -eq 0 ]; then
        log "âœ“ å¤‡ä»½åŠ å¯†å®Œæˆ"
        rm "$backup_file"
    else
        error "å¤‡ä»½åŠ å¯†å¤±è´¥"
        return 1
    fi
}

# ====================
# è¿œç¨‹å¤‡ä»½ä¸Šä¼ 
# ====================

upload_backup() {
    local backup_path="$1"
    
    log "ä¸Šä¼ å¤‡ä»½åˆ°è¿œç¨‹å­˜å‚¨..."
    
    if [ -n "$S3_BUCKET" ]; then
        upload_to_s3 "$backup_path"
    elif [ -n "$REMOTE_HOST" ]; then
        upload_to_remote "$backup_path"
    else
        warn "æœªé…ç½®è¿œç¨‹å­˜å‚¨"
    fi
}

upload_to_s3() {
    local backup_path="$1"
    local backup_file=$(find "$BACKUP_DIR" -name "$(basename "$backup_path")*" -type f | head -n 1)
    
    if command -v aws &> /dev/null; then
        aws s3 cp "$backup_file" "s3://${S3_BUCKET}/backups/"
        log "âœ“ å¤‡ä»½å·²ä¸Šä¼ åˆ° S3"
    else
        error "AWS CLI æœªå®‰è£…"
    fi
}

upload_to_remote() {
    local backup_path="$1"
    local backup_file=$(find "$BACKUP_DIR" -name "$(basename "$backup_path")*" -type f | head -n 1)
    
    if command -v scp &> /dev/null; then
        scp "$backup_file" "${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PATH}/"
        log "âœ“ å¤‡ä»½å·²ä¸Šä¼ åˆ°è¿œç¨‹æœåŠ¡å™¨"
    else
        error "SCP å‘½ä»¤æœªæ‰¾åˆ°"
    fi
}

# ====================
# å¤‡ä»½æ¢å¤
# ====================

restore_backup() {
    local backup_target="$1"
    
    if [ -z "$backup_target" ]; then
        list_backups
        echo
        read -p "è¯·è¾“å…¥è¦æ¢å¤çš„å¤‡ä»½åç§°: " backup_target
    fi
    
    local backup_path="${BACKUP_DIR}/${backup_target}"
    
    if [ ! -d "$backup_path" ] && [ ! -f "${backup_path}.tar.gz" ]; then
        error "å¤‡ä»½ä¸å­˜åœ¨: $backup_target"
        return 1
    fi
    
    log "å¼€å§‹æ¢å¤å¤‡ä»½: $backup_target"
    
    # è§£å‹å¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if [ -f "${backup_path}.tar.gz" ]; then
        log "è§£å‹å¤‡ä»½æ–‡ä»¶..."
        cd "$BACKUP_DIR"
        tar -xzf "${backup_target}.tar.gz"
    fi
    
    # ç¡®è®¤æ¢å¤æ“ä½œ
    echo -e "${YELLOW}è­¦å‘Š: æ¢å¤æ“ä½œå°†è¦†ç›–ç°æœ‰æ•°æ®ï¼${NC}"
    read -p "ç¡®è®¤ç»§ç»­æ¢å¤? (y/N): " -n 1 -r
    echo
    
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log "ç”¨æˆ·å–æ¶ˆæ¢å¤æ“ä½œ"
        return 0
    fi
    
    # åœæ­¢æœåŠ¡
    log "åœæ­¢æœåŠ¡..."
    docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" down
    
    # æ¢å¤ MySQL
    if [ -f "${backup_path}/mysql_backup.sql" ]; then
        log "æ¢å¤ MySQL æ•°æ®..."
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" up -d mysql-primary
        sleep 30
        
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" exec -T mysql-primary \
            mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" < "${backup_path}/mysql_backup.sql"
        
        log "âœ“ MySQL æ•°æ®æ¢å¤å®Œæˆ"
    fi
    
    # æ¢å¤ Redis
    if [ -f "${backup_path}/redis_dump.rdb" ]; then
        log "æ¢å¤ Redis æ•°æ®..."
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" up -d redis-master
        sleep 10
        
        local container_id=$(docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" ps -q redis-master)
        docker cp "${backup_path}/redis_dump.rdb" "$container_id:/data/dump.rdb"
        docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" restart redis-master
        
        log "âœ“ Redis æ•°æ®æ¢å¤å®Œæˆ"
    fi
    
    # æ¢å¤æ–‡ä»¶ç³»ç»Ÿ
    if [ -f "${backup_path}/filesystem.tar" ]; then
        log "æ¢å¤æ–‡ä»¶ç³»ç»Ÿ..."
        tar -xf "${backup_path}/filesystem.tar" -C "$PROJECT_ROOT"
        log "âœ“ æ–‡ä»¶ç³»ç»Ÿæ¢å¤å®Œæˆ"
    fi
    
    # é‡å¯æ‰€æœ‰æœåŠ¡
    log "é‡å¯æ‰€æœ‰æœåŠ¡..."
    docker-compose -f "${PROJECT_ROOT}/${COMPOSE_FILE}" up -d
    
    log "ğŸ‰ å¤‡ä»½æ¢å¤å®Œæˆ"
}

# ====================
# åˆ—å‡ºå¤‡ä»½
# ====================

list_backups() {
    log "å¤‡ä»½æ–‡ä»¶åˆ—è¡¨:"
    echo
    
    printf "%-30s %-12s %-15s %-10s\n" "å¤‡ä»½åç§°" "ç±»å‹" "åˆ›å»ºæ—¶é—´" "å¤§å°"
    echo "=================================================================="
    
    for backup in $(ls -1 "$BACKUP_DIR" | grep -E "(full_backup_|incremental_backup_)" | sort -r); do
        local backup_path="${BACKUP_DIR}/${backup}"
        local backup_type="æœªçŸ¥"
        local backup_time="æœªçŸ¥"
        local backup_size="æœªçŸ¥"
        
        if [ -f "${backup_path}/backup_info.json" ]; then
            backup_type=$(jq -r '.backup_type // "unknown"' "${backup_path}/backup_info.json")
            backup_time=$(jq -r '.started_at // "unknown"' "${backup_path}/backup_info.json" | cut -dT -f1)
        fi
        
        if [ -d "$backup_path" ]; then
            backup_size=$(du -sh "$backup_path" | awk '{print $1}')
        elif [ -f "${backup_path}.tar.gz" ]; then
            backup_size=$(du -sh "${backup_path}.tar.gz" | awk '{print $1}')
        fi
        
        printf "%-30s %-12s %-15s %-10s\n" "$backup" "$backup_type" "$backup_time" "$backup_size"
    done
}

# ====================
# æ¸…ç†è¿‡æœŸå¤‡ä»½
# ====================

cleanup_backups() {
    log "æ¸…ç†è¿‡æœŸå¤‡ä»½ (ä¿ç•™ $RETENTION_DAYS å¤©)..."
    
    local deleted_count=0
    local total_size=0
    
    find "$BACKUP_DIR" -name "*backup_*" -type d -mtime +$RETENTION_DAYS -print0 | \
    while IFS= read -r -d '' backup_path; do
        local size=$(du -s "$backup_path" | awk '{print $1}')
        total_size=$((total_size + size))
        
        log "åˆ é™¤è¿‡æœŸå¤‡ä»½: $(basename "$backup_path")"
        rm -rf "$backup_path"
        deleted_count=$((deleted_count + 1))
    done
    
    # æ¸…ç†å‹ç¼©æ–‡ä»¶
    find "$BACKUP_DIR" -name "*backup_*.tar.gz" -type f -mtime +$RETENTION_DAYS -delete
    
    if [ $deleted_count -gt 0 ]; then
        log "âœ“ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† $deleted_count ä¸ªè¿‡æœŸå¤‡ä»½"
        log "é‡Šæ”¾ç©ºé—´: $(echo "$total_size * 1024" | bc | numfmt --to=iec-i --suffix=B)"
    else
        log "æ²¡æœ‰éœ€è¦æ¸…ç†çš„è¿‡æœŸå¤‡ä»½"
    fi
}

# ====================
# éªŒè¯å¤‡ä»½å®Œæ•´æ€§
# ====================

verify_backup() {
    local backup_target="$1"
    
    if [ -z "$backup_target" ]; then
        list_backups
        echo
        read -p "è¯·è¾“å…¥è¦éªŒè¯çš„å¤‡ä»½åç§°: " backup_target
    fi
    
    local backup_path="${BACKUP_DIR}/${backup_target}"
    
    if [ ! -d "$backup_path" ] && [ ! -f "${backup_path}.tar.gz" ]; then
        error "å¤‡ä»½ä¸å­˜åœ¨: $backup_target"
        return 1
    fi
    
    log "éªŒè¯å¤‡ä»½å®Œæ•´æ€§: $backup_target"
    
    local verification_passed=true
    
    # éªŒè¯å¤‡ä»½ä¿¡æ¯æ–‡ä»¶
    if [ -f "${backup_path}/backup_info.json" ]; then
        if jq empty "${backup_path}/backup_info.json" 2>/dev/null; then
            log "âœ“ å¤‡ä»½ä¿¡æ¯æ–‡ä»¶æ ¼å¼æ­£ç¡®"
        else
            error "âœ— å¤‡ä»½ä¿¡æ¯æ–‡ä»¶æ ¼å¼é”™è¯¯"
            verification_passed=false
        fi
    else
        warn "å¤‡ä»½ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨"
    fi
    
    # éªŒè¯ MySQL å¤‡ä»½
    if [ -f "${backup_path}/mysql_backup.sql" ]; then
        if [ -f "${backup_path}/mysql_info.json" ]; then
            local stored_checksum=$(jq -r '.checksum' "${backup_path}/mysql_info.json")
            local actual_checksum=$(md5sum "${backup_path}/mysql_backup.sql" | awk '{print $1}')
            
            if [ "$stored_checksum" = "$actual_checksum" ]; then
                log "âœ“ MySQL å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡"
            else
                error "âœ— MySQL å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥"
                verification_passed=false
            fi
        else
            warn "MySQL å¤‡ä»½ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨"
        fi
    fi
    
    # éªŒè¯ Redis å¤‡ä»½
    if [ -f "${backup_path}/redis_dump.rdb" ]; then
        if [ -f "${backup_path}/redis_info.json" ]; then
            local stored_checksum=$(jq -r '.checksum' "${backup_path}/redis_info.json")
            local actual_checksum=$(md5sum "${backup_path}/redis_dump.rdb" | awk '{print $1}')
            
            if [ "$stored_checksum" = "$actual_checksum" ]; then
                log "âœ“ Redis å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡"
            else
                error "âœ— Redis å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥"
                verification_passed=false
            fi
        else
            warn "Redis å¤‡ä»½ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨"
        fi
    fi
    
    if [ "$verification_passed" = true ]; then
        log "ğŸ‰ å¤‡ä»½å®Œæ•´æ€§éªŒè¯é€šè¿‡"
    else
        error "å¤‡ä»½å®Œæ•´æ€§éªŒè¯å¤±è´¥"
        return 1
    fi
}

# ====================
# è®¾ç½®è‡ªåŠ¨å¤‡ä»½
# ====================

schedule_backup() {
    log "è®¾ç½®è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡..."
    
    local cron_entry="0 2 * * * $SCRIPT_DIR/backup.sh full >> $PROJECT_ROOT/logs/backup-cron.log 2>&1"
    
    echo "å»ºè®®çš„ crontab æ¡ç›®:"
    echo "$cron_entry"
    echo
    
    read -p "æ˜¯å¦è¦è‡ªåŠ¨æ·»åŠ åˆ° crontab? (y/N): " -n 1 -r
    echo
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        (crontab -l 2>/dev/null; echo "$cron_entry") | crontab -
        log "âœ“ è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡å·²æ·»åŠ åˆ° crontab"
        log "æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œå…¨é‡å¤‡ä»½"
    else
        log "è¯·æ‰‹åŠ¨æ·»åŠ  crontab æ¡ç›®ä»¥å¯ç”¨è‡ªåŠ¨å¤‡ä»½"
    fi
}

# ====================
# ä¸»å‡½æ•°
# ====================

main() {
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    mkdir -p "${PROJECT_ROOT}/logs"
    
    log "å¯åŠ¨å¤‡ä»½ç³»ç»Ÿ..."
    log "æ“ä½œ: $OPERATION"
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_prerequisites
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    if [ -f "${PROJECT_ROOT}/.env" ]; then
        source "${PROJECT_ROOT}/.env"
    fi
    
    case $OPERATION in
        full)
            full_backup
            ;;
        incremental)
            incremental_backup
            ;;
        restore)
            restore_backup "$RESTORE_TARGET"
            ;;
        list)
            list_backups
            ;;
        cleanup)
            cleanup_backups
            ;;
        verify)
            verify_backup "$RESTORE_TARGET"
            ;;
        schedule)
            schedule_backup
            ;;
        *)
            error "æœªçŸ¥æ“ä½œ: $OPERATION"
            exit 1
            ;;
    esac
    
    log "å¤‡ä»½æ“ä½œå®Œæˆ"
}

# è§£æå‚æ•°å¹¶æ‰§è¡Œ
parse_arguments "$@"
main